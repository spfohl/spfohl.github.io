---
permalink: /
title: "Stephen Pfohl"
excerpt: "Stephen Pfohl"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a senior research scientist at Google Research. My work focuses on the incorporation of fairness, distribution shift, and equity considerations into the design and evaluation of machine learning systems in healthcare contexts. Previously, I completed a PhD in Biomedical Informatics at Stanford University in the Department of Biomedical Data Science. 
<br><br>
For a complete list of publications, see my <a href="https://scholar.google.com/citations?user=Q0YPo5IAAAAJ&hl=en">Google Scholar</a> page.

Select Publications  
===

<a href="https://www.nature.com/articles/s41591-024-03258-2">A toolbox for surfacing health equity harms and biases in large language models</a>
<br>
<b>Stephen R. Pfohl</b>\*, Heather Cole-Lewis\*, Rory Sayres, Darlene Neal, Mercy Asiedu, Awa Dieng, Nenad Tomasev, Qazi Mamunur Rashid, Shekoofeh Azizi, Negar Rostamzadeh, Liam G. McCoy, Leo Anthony Celi, Yun Liu, Mike Schaekermann, Alanna Walton, Alicia Parrish, Chirag Nagpal, Preeti Singh, Akeiylah Dewitt, Philip Mansfield, Sushant Prakash, Katherine Heller, Alan Karthikesalingam, Christopher Semturs, Joelle Barral, Greg Corrado, Yossi Matias, Jamila Smith-Loud, Ivor Horn & Karan Singhal
<br>
<i>Nature Medicine (2024)</i>
<br>
\[<a href="https://www.nature.com/articles/s41591-024-03258-2">paper</a>\] \[<a href="https://www.nature.com/articles/s41591-024-03258-2.pdf">pdf</a>\]


<a href="https://dl.acm.org/doi/abs/10.1145/3630106.3658972">A Causal Perspective on Label Bias</a>
<br>
Vishwali Mhasawade, Alexander D'Amour, <b>Stephen R. Pfohl</b>
<br>
<i>FAccT '24: The 2024 ACM Conference on Fairness, Accountability, and Transparency</i>
<br>
\[<a href="https://dl.acm.org/doi/abs/10.1145/3630106.3658972">paper</a>\] \[<a href="https://dl.acm.org/doi/pdf/10.1145/3630106.3658972">pdf</a>\]

<a href="https://proceedings.mlr.press/v238/tsai24b.html">Proxy Methods for Domain Adaptation</a>
<br>
Katherine Tsai, <b>Stephen R. Pfohl</b>, Olawale Salaudeen, Nicole Chiou, Matt Kusner, Alexander D’Amour, Sanmi Koyejo, Arthur Gretton
<br>
<i>Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, PMLR 238:3961-3969, 2024.</i>
<br>
\[<a href="https://proceedings.mlr.press/v238/tsai24b.html">paper</a>\] \[<a href="https://proceedings.mlr.press/v238/tsai24b/tsai24b.pdf">pdf</a>\]

<a href="https://openreview.net/forum?id=Fd00jISBD0">Understanding subgroup performance differences of fair predictors using causal models</a>
<br>
<b>Stephen R. Pfohl</b>, Natalie Harris, Chirag Nagpal, David Madras, Vishwali Mhasawade, Olawale Salaudeen, Katherine Heller, Sanmi Koyejo, Alexander D'Amour
<br>
<i>NeurIPS 2023 Workshop on Distribution Shifts: New Frontiers with Foundation Models</i>
<br>
\[<a href="https://openreview.net/forum?id=Fd00jISBD0">paper</a>\] \[<a href="https://openreview.net/pdf?id=Fd00jISBD0">pdf</a>\]

<a href="https://proceedings.mlr.press/v206/alabdulmohsin23a">Adapting to Latent Subgroup Shifts via Concepts and Proxies</a>
<br>
Ibrahim Alabdulmohsin, Nicole Chiou, Alexander D’Amour, Arthur Gretton, Sanmi Koyejo, Matt J. Kusner, <b>Stephen R. Pfohl</b>, Olawale Salaudeen, Jessica Schrouff, Katherine Tsai
<br>
<i>Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, PMLR 206:9637-9661, 2023</i>
<br>
Equal contribution; authors listed alphabetically.
<br>
\[<a href="https://proceedings.mlr.press/v206/alabdulmohsin23a">paper</a>\] \[<a href="https://proceedings.mlr.press/v206/alabdulmohsin23a/alabdulmohsin23a.pdf">pdf</a>\]

<a href="https://arxiv.org/abs/2202.01906">Net benefit, calibration, threshold selection, and training objectives for algorithmic fairness in healthcare</a>
<br>
<b>Stephen R. Pfohl</b>, Yizhe Xu, Agata Foryciarz, Nikolaos Ignatiadis, Julian Genkins, Nigam H. Shah
<br>
<i>ACM Conference on Fairness Accountability and Transparency (FAccT) 2022</i>
<br>
\[<a href="https://arxiv.org/abs/2202.01906">preprint</a>\] \[<a href="https://dl.acm.org/doi/abs/10.1145/3531146.3533166">paper</a>\] \[<a href="https://spfohl.github.io/files/pfohl_net_benefit_combined.pdf">pdf</a>\]


<a href="https://searchworks.stanford.edu/view/14051829">Recommendations for algorithmic fairness assessments of predictive models in healthcare: evidence from large-scale empirical analyses</a>
<br>
<b>Stephen R. Pfohl</b>
<br>
\[<a href="https://searchworks.stanford.edu/view/14051829">dissertation</a>\] \[<a href="https://spfohl.github.io/files/pfohl-dissertation.pdf">pdf</a>\] \[<a href="https://spfohl.github.io/files/defense_slides_20211112.pdf">slides</a>\] [![CC BY 4.0][cc-by-image]][cc-by]

<a href="https://www.medrxiv.org/content/10.1101/2021.11.08.21266076v2">Evaluating algorithmic fairness in the presence of clinical guidelines: the case of atherosclerotic cardiovascular disease risk estimation</a>
<br>
Agata Foryciarz, <b>Stephen R. Pfohl</b>, Birju Patel, Nigam H. Shah
<br>
<i>BMJ Health & Care Informatics 29, e100460</i>
<br>
\[<a href="https://www.medrxiv.org/content/10.1101/2021.11.08.21266076v2">preprint</a>\] \[<a href="https://informatics.bmj.com/content/29/1/e100460">paper</a>\]

<a href="https://www.nature.com/articles/s41598-022-07167-7">A comparison of approaches to improve worst-case predictive model performance over patient subpopulations</a>
<br>
<b>Stephen R. Pfohl</b>, Haoran Zhang, Yizhe Xu, Agata Foryciarz, Marzyeh Ghassemi, Nigam H. Shah.
<br>
<i>Scientific Reports 12 (1), 1-13, 2022</i>
<br>
\[<a href="https://www.nature.com/articles/s41598-022-07167-7">paper</a>\] \[<a href="https://arxiv.org/abs/2108.12250">preprint</a>\] \[<a href="https://github.com/som-shahlab/subpopulation_robustness">code</a>\]


<a href="https://www.sciencedirect.com/science/article/abs/pii/S1532046420302495">An Empirical Characterization of Fair Machine Learning For Clinical Risk Prediction</a>
<br>
<b>Stephen R. Pfohl</b>, Agata Foryciarz, Nigam H. Shah.
<br>
<i>Journal of Biomedical Informatics, 113:103621, 2021</i>
<br>
\[<a href="https://www.sciencedirect.com/science/article/abs/pii/S1532046420302495">paper</a>\] \[<a href="https://arxiv.org/abs/2007.10306">preprint</a>\] \[<a href="https://github.com/som-shahlab/fairness_benchmark">code</a>\]


<!-- [![CC BY 4.0][cc-by-image]][cc-by]
Works not licensed under a more restrictive license are licensed under
[Creative Commons Attribution 4.0 International License][cc-by]. -->

[cc-by]: http://creativecommons.org/licenses/by/4.0/
[cc-by-image]: https://i.creativecommons.org/l/by/4.0/88x31.png
[cc-by-shield]: https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg